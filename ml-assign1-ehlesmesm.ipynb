{
 "metadata": {
  "name": "ml-assign1-ehlesmesm"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Assignment 1"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Linear Algebra and Probability"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Getting Started With Python For Data Science"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from numpy import genfromtxt, savetxt\n",
      "\n",
      "#create the training & test sets, skipping the header row with [1:]\n",
      "dataset = genfromtxt(open('Data/train.csv','r'), delimiter=',', dtype='f8')[1:]    \n",
      "target = [x[0] for x in dataset]\n",
      "train = [x[1:] for x in dataset]\n",
      "test = genfromtxt(open('Data/test.csv','r'), delimiter=',', dtype='f8')[1:]\n",
      "\n",
      "#create and train the random forest\n",
      "#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "rf.fit(train, target)\n",
      "predicted_probs = [[index + 1, x[1]] for index, x in enumerate(rf.predict_proba(test))]\n",
      "\n",
      "savetxt('Data/submission_rfc.csv', predicted_probs, delimiter=',', fmt='%d,%f', \n",
      "        header='MoleculeId,PredictedProbability', comments = '')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn import cross_validation\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "\n",
      "\n",
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll\n",
      "\n",
      "\n",
      "dataset = np.genfromtxt(open('Data/train.csv','r'), delimiter=',', dtype='f8')[1:]    \n",
      "target = np.array([x[0] for x in dataset])\n",
      "train = np.array([x[1:] for x in dataset])\n",
      "\n",
      "cfr = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
      "...     max_depth=1, random_state=0)\n",
      "cfr.fit(train, target)\n",
      "\n",
      "predicted_probs = [[index + 1, x[1]] for index, x in enumerate(cfr.predict_proba(test))]\n",
      "\n",
      "savetxt('Data/submission_gbc.csv', predicted_probs, delimiter=',', fmt='%d,%f', \n",
      "        header='MoleculeId,PredictedProbability', comments = '')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "\n",
      "\n",
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll\n",
      "\n",
      "\n",
      "#read in  data, parse into training and target sets\n",
      "dataset = np.genfromtxt(open('Data/train.csv','r'), delimiter=',', dtype='f8')[1:]    \n",
      "target = np.array([x[0] for x in dataset])\n",
      "train = np.array([x[1:] for x in dataset])\n",
      "\n",
      "#In this case we'll use a random forest, but this could be any classifier\n",
      "cfr = RandomForestClassifier(n_estimators=100)\n",
      "\n",
      "#Simple K-Fold cross validation. 5 folds.\n",
      "#(Note: in older scikit-learn versions the \"n_folds\" argument is named \"k\".)\n",
      "cv = cross_validation.KFold(len(train), n_folds=5, indices=False)\n",
      "\n",
      "#iterate through the training and test cross validation segments and\n",
      "#run the classifier on each one, aggregating the results into a list\n",
      "results = []\n",
      "for traincv, testcv in cv:\n",
      "    probas = cfr.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\n",
      "    results.append( llfun(target[testcv], [x[1] for x in probas]) )\n",
      "\n",
      "#print out the mean of the cross-validated results\n",
      "print \"Results: \" + str( np.array(results).mean() )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Results: 0.458622986874\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn import cross_validation\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "\n",
      "\n",
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll\n",
      "\n",
      "\n",
      "dataset = np.genfromtxt(open('Data/train.csv','r'), delimiter=',', dtype='f8')[1:]    \n",
      "target = np.array([x[0] for x in dataset])\n",
      "train = np.array([x[1:] for x in dataset])\n",
      "\n",
      "cfr = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
      "...     max_depth=1, random_state=0)\n",
      "\n",
      "cv = cross_validation.KFold(len(train), n_folds=5, indices=False)\n",
      "\n",
      "results = []\n",
      "for traincv, testcv in cv:\n",
      "    probas = cfr.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\n",
      "    results.append( llfun(target[testcv], [x[1] for x in probas]) )\n",
      "\n",
      "#print out the mean of the cross-validated results\n",
      "print \"Results: \" + str( np.array(results).mean() )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Results: 0.549980445344\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Linear Algebra and Probability"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Joint Probability $P(T,D)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The joint probability of selecting the $i$-th term from the $j$-th document is given by $P(t_i,d_j) = \\frac{1}{n}\\frac{TD_{ij}}{\\sum_{k=1}^m TD_{kj}} = \\frac{1}{n}P(t_i|d_j)$, so that $P(T,D)=\\frac{1}{n}P(T|D)$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Conditional Probability $P(T|D)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The conditional probability of selecting the $i$-th term given that we've selected the $j$-th document is given by $P(t_i|d_j) = \\frac{TD_{ij}}{\\sum_{k=1}^m TD_{kj}}$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Conditional Probability $P(D|T)$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bayes' theorem says that $P(d_i|t_j) = \\frac{P(d_i) P(t_j|d_i)}{P(t_j)}$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Probability of Terms $P(T)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because of the Law of Total Probability, the probability of the $i$-th term is given by $P(t_i) = \\sum_{j=1}^n P(t_i,d_j)$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Probability of Documents $P(D)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because of the Lawo of Total Probability, the probability of the $j$-th document is given by $P(d_j)=\\sum_{i=1}^m P(t_i, d_j)$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Expected Terms' Length $E(L)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The expected length of a term is given by $E[L]=\\sum_{i=1}^m P(t_i) l_i$, where $l_i$ is the length of the $i$-th term. This is just the dot product of $P(T)$ and $L$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Variance of Terms' Length $Var(L)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The variance is given by $Var(L)=\\sum_{i=1}^m P(t_i)(l_i-E[L])^2$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Numpy Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from IPython.display import display, Math, Latex\n",
      "\n",
      "\n",
      "n = 5\n",
      "m = 6\n",
      "\n",
      "TD_mxn = np.array(\\\n",
      "[[2., 3., 0., 3., 7.],\n",
      " [0., 5., 5., 0., 3],\n",
      " [5., 0., 7., 3., 3],\n",
      " [3., 1., 0., 9., 9],\n",
      " [0., 0., 7., 1., 3],\n",
      " [6., 9., 4., 6., 0]])\n",
      "\n",
      "L_mx1 = np.array(\\\n",
      "[[5],\n",
      " [2],\n",
      " [3],\n",
      " [6],\n",
      " [4],\n",
      " [3]])\n",
      "\n",
      "\n",
      "### Some useful constants\n",
      "\n",
      "ones_1xm = np.array([[1] * m])\n",
      "ones_mx1 = np.array([[1]] * m)\n",
      "\n",
      "ones_1xn = np.array([[1] * n])\n",
      "ones_nx1 = np.array([[1]] * n)\n",
      "\n",
      "\n",
      "### Conditional Probability P(T|D)\n",
      "\n",
      "termcount_1xn = np.dot(ones_1xm, TD_mxn)\n",
      "termcount_mxn = np.dot(ones_mx1, termcount_1xn) \n",
      "\n",
      "ProbTGivenD_mxn = np.divide(TD_mxn, termcount_mxn)\n",
      "\n",
      "display(Math(r'P(T|D)='))\n",
      "print ProbTGivenD_mxn\n",
      "print\n",
      "\n",
      "\n",
      "### Joint Probability P(T,D)\n",
      "\n",
      "JointProb_mxn = np.divide(ProbTGivenD_mxn, n) \n",
      "display(Math(r'P(T,D)='))\n",
      "print JointProb_mxn\n",
      "print\n",
      "\n",
      "\n",
      "### Terms' Probability\n",
      "\n",
      "ProbTerms_mx1 = np.dot(JointProb_mxn, ones_nx1)\n",
      "display(Math(r'P(T)='))\n",
      "print ProbTerms_mx1\n",
      "print\n",
      "\n",
      "\n",
      "### Documents' Probability\n",
      "\n",
      "ProbDocs_1xn = np.dot(ones_1xm, JointProb_mxn)\n",
      "display(Math(r'P(D)='))\n",
      "print ProbDocs_1xn\n",
      "print\n",
      "\n",
      "\n",
      "### Conditional Probability P(D|T)\n",
      "\n",
      "ProbTerms_nxm = np.dot(ones_nx1, np.transpose(ProbTerms_mx1))\n",
      "ProbDocs_nxm = np.dot(np.transpose(ProbDocs_1xn), ones_1xm)\n",
      "\n",
      "ProbDGivenT_nxm = np.divide(np.multiply(np.transpose(ProbTGivenD_mxn), ProbDocs_nxm), ProbTerms_nxm)\n",
      "display(Math(r'P(D|T)='))\n",
      "print ProbDGivenT_nxm\n",
      "print\n",
      "\n",
      "\n",
      "### Expected Value E(L)\n",
      "\n",
      "ExpL_1x1 = np.dot(np.transpose(ProbTerms_mx1), L_mx1)\n",
      "display(Math(r'E[L]='))\n",
      "print ExpL_1x1\n",
      "print\n",
      "\n",
      "\n",
      "### Variance Var(L)\n",
      "\n",
      "VarL_1x1 = np.dot(np.transpose(ProbTerms_mx1), (L_mx1 - np.multiply(ExpL_1x1, ones_mx1))**2)\n",
      "display(Math(r'Var(L)'))\n",
      "print VarL_1x1\n",
      "print\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "$$P(T|D)=$$"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Math at 0x54b8ad0>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.125       0.16666667  0.          0.13636364  0.28      ]\n",
        " [ 0.          0.27777778  0.2173913   0.          0.12      ]\n",
        " [ 0.3125      0.          0.30434783  0.13636364  0.12      ]\n",
        " [ 0.1875      0.05555556  0.          0.40909091  0.36      ]\n",
        " [ 0.          0.          0.30434783  0.04545455  0.12      ]\n",
        " [ 0.375       0.5         0.17391304  0.27272727  0.        ]]\n",
        "\n"
       ]
      },
      {
       "latex": [
        "$$P(T,D)=$$"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Math at 0x54b8d90>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.025       0.03333333  0.          0.02727273  0.056     ]\n",
        " [ 0.          0.05555556  0.04347826  0.          0.024     ]\n",
        " [ 0.0625      0.          0.06086957  0.02727273  0.024     ]\n",
        " [ 0.0375      0.01111111  0.          0.08181818  0.072     ]\n",
        " [ 0.          0.          0.06086957  0.00909091  0.024     ]\n",
        " [ 0.075       0.1         0.03478261  0.05454545  0.        ]]\n",
        "\n"
       ]
      },
      {
       "latex": [
        "$$P(T)=$$"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Math at 0x54b8e50>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.14160606]\n",
        " [ 0.12303382]\n",
        " [ 0.17464229]\n",
        " [ 0.20242929]\n",
        " [ 0.09396047]\n",
        " [ 0.26432806]]\n",
        "\n"
       ]
      },
      {
       "latex": [
        "$$P(D)=$$"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Math at 0x54b8c90>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.2  0.2  0.2  0.2  0.2]]\n",
        "\n"
       ]
      },
      {
       "latex": [
        "$$P(D|T)=$$"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Math at 0x54b8c90>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.17654612  0.          0.35787437  0.18524987  0.          0.28373832]\n",
        " [ 0.23539482  0.45154704  0.          0.05488885  0.          0.37831776]\n",
        " [ 0.          0.35338464  0.34853851  0.          0.64782097  0.13158879]\n",
        " [ 0.19259576  0.          0.15616336  0.40418153  0.09675248  0.20635514]\n",
        " [ 0.3954633   0.19506832  0.13742376  0.35567975  0.25542655  0.        ]]\n",
        "\n"
       ]
      },
      {
       "latex": [
        "$$E[L]=$$"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Math at 0x54b8c90>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 3.86142666]]\n",
        "\n"
       ]
      },
      {
       "latex": [
        "$$Var(L)$$"
       ],
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Math at 0x54b8c90>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.86322628]]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}